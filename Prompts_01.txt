Progress update — pipeline rerun + confounding check

What I ran

Re-ran the whole pipeline on your updated IncomeNormalized CSV:
python3 [analysis_scales.py](http://_vscodecontentref_/3) InputData/...-IncomeNormalized.csv — regenerated scales_summary.csv, numeric_stats.csv, categorical_summary.csv, scales_analysis_report.txt, and an analysis-ready CSV.
python3 [remove_outliers_and_regen.py](http://_vscodecontentref_/4) InputData/...-IncomeNormalized.csv — using the relaxed rule (remove rows only if outlier in >=2 numeric cols); saved ...-NoOutliers.csv (shape changed from 104→79 rows) and started regenerating plots/PDF under plots and scales_plots_report_nooutliers.pdf.
python3 [relational_analysis.py](http://_vscodecontentref_/7) InputData/...-NoOutliers.csv — updated script used SciPy for exact tests and wrote relation_summary.csv and relation_report.pdf. I then applied Benjamini–Hochberg FDR to the relation summary and wrote relation_summary_with_fdr.csv.
Quick results (files created / updated)

New NoOutliers CSV: 20251214-ScalesData-Combined_ver0.7-Cleaned-IncomeNormalized-NoOutliers.csv (79 rows × 75 cols)
Relation test summary (raw): relation_summary.csv
Relation summary with FDR (BH): relation_summary_with_fdr.csv
Total tested p-values parsed: 117
Significant at FDR 0.05: 85 tests
Plots:
Per-variable NoOutliers plots: InputData/outputs_nooutliers/plots/
Relation pair plots (including marital-status snapshot images): InputData/outputs_relation/plots/
Reports:
Per-variable PDF (NoOutliers): scales_plots_report_nooutliers.pdf (script wrote it)
Relation PDF: relation_report.pdf
Confounding / adjusted analysis I ran (one focused example)

I installed statsmodels and fit linear models for:
Exposure: "Withdrawl - Weighted Score"
Outcome: "Perceived Social Support Total T Score"
Covariates: Age (IN YEARS), Monthly household income_midpoint_INR, Highest level of education completed, Marital Status
Crude model:
beta (Withdrawl) = -1.796, p ≈ 9.8e-06
Adjusted model (covariates included):
beta (Withdrawl) = -1.660, p ≈ 0.00121
R2 reported in the saved summary
Interaction model (Withdrawl * Marital Status):
Main effect for base group ≈ -2.909 (p ≈ 0.0047)
Interaction term (Single vs base): +1.652 (p ≈ 0.126)
Interpretation: effect is stronger (more negative) in the base marital group; the interaction p-value ~0.13 (not significant at 0.05).
Files saved for these models:

adjusted_models_summary.csv — contains crude vs adjusted effect (Withdrawl → Perceived Social Support T Score) and adjusted R2.
Interpretation — short

Withdrawal (internet-withdrawal score) is negatively associated with perceived social support in the NoOutliers sample. The association remains after adjusting for age, income, education, and marital status (effect size reduced slightly from -1.796 to -1.660, but remains statistically significant).
The interaction test suggests the negative association may be stronger in one marital group (base category) than the other, but the interaction term is not statistically significant (p ≈ 0.13).
Many pairwise tests are significant after FDR correction (85 / 117). This is expected given many related scales and correlated measures in psychometric data.
Causal claim? Not supported by these cross-sectional associations alone. Adjustment for confounders reduces bias but cannot rule out residual/unmeasured confounding, reverse causality, or selection bias. I list practical next steps below.
Notes, warnings and small fixes

I added BH FDR correction by parsing numeric p-values from relation_summary.csv and writing relation_summary_with_fdr.csv.
The relation-plot generation emits seaborn FutureWarnings about passing palette without hue; harmless for now but we could tidy plots to silence warnings.
I installed statsmodels to run OLS regressions; requirements.txt can be updated to include it (I can add it).
The outlier plotting stage can take time (many figures). I let the scripts run to completion for each main step.
Recommended next steps (pick any)

Produce adjusted regression results for a predefined list of exposure→outcome pairs (not just Withdrawl → Perceived Social Support). I can batch-run OLS models with the same covariates for all internet-related exposures and the top dependent scores, then FDR-correct the exposure p-values across those models.
Add a CLI to remove_outliers_and_regen.py so you can easily choose min_outlier_cols and iqr_multiplier interactively; I can implement this quickly.
Replace row-removal with winsorization (cap outliers) and re-run relational analyses so you keep full sample but reduce influence of extremes.
Create a short one-page PDF summary showing:
Top 6 associations (plots + BH-adjusted p-values)
Results of 1-2 adjusted regression models (coef, 95% CI, p)
Short confounding & causal assessment
If you want causal claims explored further: we can build small DAG(s) from domain knowledge and do:
regression with covariate adjustment per the DAG,
stratified sensitivity analyses,
or (if you have candidate instruments) attempt IV estimation.
Which next step should I run now?

I can (A) run step 1 to batch-fit adjusted models for all internet-related exposures → chosen outcomes and write a results CSV (very quick), or (B) implement a CLI for outlier script, or (C) create the one-page PDF summary (will generate plots & text).
Tell me A, B, or C (or a combination) and I’ll proceed and attach the new files.
GPT-5 mini • 0x


===========================================================================================================================




Below is a plain‑English, step‑by‑step walkthrough of everything I did for the analysis (what each script does, the statistical choices made, files produced, how confounding and causal questions were handled, and how you can re-run or change behavior). I kept it practical so you can reproduce or modify each step.

High-level pipeline (what I ran)
Start with your cleaned Income‑normalized CSV:
20251214-ScalesData-Combined_ver0.7-Cleaned-IncomeNormalized.csv
Run the automated descriptive analysis: analysis_scales.py
Remove extreme rows (outliers) and regenerate per-variable plots: remove_outliers_and_regen.py
Run pairwise relational/statistical analysis and produce plots + summary: relational_analysis.py
Run targeted adjusted regression(s) to check confounding and interactions (I used statsmodels in a quick script block and saved results).
Files I used and produced (quick map)
Inputs
InputData/...-IncomeNormalized.csv (your main cleaned/normalized dataset)
InputData/...-IncomeNormalized-NoOutliers.csv (generated by the outlier script)
Descriptive outputs (from analysis_scales.py)
scales_summary.csv (per-column summary)
numeric_stats.csv (numeric column stats, IQR/outlier counts)
categorical_summary.csv (top categories)
scales_analysis_report.txt (human-readable summary)
InputData/...-analysis-ready.csv (a copy saved for downstream plotting)
Outlier-clean outputs (from remove_outliers_and_regen.py)
InputData/...-NoOutliers.csv (new dataset after outlier removal; with relaxed rule this is 79 rows)
InputData/outputs_nooutliers/plots/ (folder with per-variable PNGs)
scales_plots_report_nooutliers.pdf (one-page-per-variable PDF)
Relational outputs (from relational_analysis.py)
InputData/outputs_relation/plots/ (pairwise plots; includes stratified snapshots by Marital Status)
relation_summary.csv (raw test results per pair)
relation_report.pdf (compiled images in a PDF)
relation_summary_with_fdr.csv (after Benjamini–Hochberg correction)
Confounding / regression outputs
adjusted_models_summary.csv (example crude vs adjusted model results I fit for Withdrawl → Perceived Social Support T Score)
Environment / reproducibility
requirements.txt (I created this and pinned SciPy 1.15.3 and core libs)
SciPy and statsmodels were installed in the environment (I installed scipy and statsmodels during the session).
Step‑by‑step — what each script does (plain English)
A. analysis_scales.py

Purpose: quick, automated descriptive scan of the IncomeNormalized CSV.
What it does:
Attempts to find the CSV header row (looks at the first ~50 lines for 'Name' etc). If not found, uses line 5 as fallback.
Reads the CSV into pandas and cleans column names (trims whitespace).
For each column it records: dtype, missing count, unique count, and a few sample values and writes scales_summary.csv.
For numeric columns it computes median, mean, std, IQR, and counts IQR-based outliers; writes numeric_stats.csv.
For categorical (object) columns it writes top categories to categorical_summary.csv.
Writes a small human-readable scales_analysis_report.txt.
Saves an analysis-ready CSV copy next to the input (same stem + "-analysis-ready.csv").
When to re-run: whenever the input CSV is modified or renamed.
B. remove_outliers_and_regen.py (modified)

Purpose: remove rows flagged as outliers and re-generate dataset-specific plots and a PDF.
Original behavior: removed a row if it was an outlier in any numeric column (very aggressive).
Change I implemented: less aggressive rule — a row is removed only if it is an outlier in at least N numeric columns (default N = 2). I also made the IQR multiplier configurable in the function.
How it flags outliers:
For each numeric column it computes IQR-based fences: q1 - kIQR and q3 + kIQR (k default 1.5).
For each row it counts how many numeric columns are outside their fences.
It keeps rows that have fewer than min_outlier_cols outlier flags (so rows with 0 or 1 flagged column are retained when min_outlier_cols=2).
Outputs:
The new CSV: InputData/...-NoOutliers.csv (with fewer rows removed than before: 79 rows with the default N=2 case).
Per-variable PNGs under InputData/outputs_nooutliers/plots/ and an aggregated PDF InputData/scales_plots_report_nooutliers.pdf.
Why this change: reduces data loss from isolated extreme values in single columns while still removing rows with multiple aberrant measurements.
C. relational_analysis.py (updated)

Purpose: automated pairwise relationship testing and plots, with stratification snapshot by marital status.
Key updates I made:
Use SciPy (pearsonr/spearmanr, f_oneway, kruskal, chi2_contingency) for exact test statistics where appropriate.
Create scatter + regression lines (overall) for numeric-numeric pairs and add a small sentinel image showing group-wise scatter/regression by Marital Status when that column exists.
For categorical vs numeric: boxplots and ANOVA (fallback to Kruskal when ANOVA fails).
For categorical vs categorical: contingency table + chi‑square.
Save pairwise PNGs and compile into a PDF.
Write a relation_summary.csv with fields: independent, dependent, test, statistic, pvalue, notes.
Post-processing I ran:
Parse numeric p-values from relation_summary.csv and apply Benjamini–Hochberg FDR (BH) correction (wrote relation_summary_with_fdr.csv).
Count: in this run, 117 tests had parsable p-values; 85 tests were significant at FDR q ≤ 0.05 (this is expected in psychometric data where many measures are correlated).
Note on plotting/warnings: seaborn produced FutureWarnings about palette usage — harmless but we can tidy visuals later.
D. Adjusted regression / confounding check (ad hoc statsmodels run)

Purpose: go beyond pairwise correlation to check whether associations persist after controlling for plausible confounders.
What I ran as an example:
Outcome: Perceived Social Support Total T Score
Exposure: Withdrawl - Weighted Score
Covariates: Age (IN YEARS), Monthly household income_midpoint_INR, Highest level of education completed, Marital Status
Models:
Crude OLS: outcome ~ exposure
Adjusted OLS: outcome ~ exposure + covariates (categorical covariates entered as C(...))
Interaction model: outcome ~ exposure * MaritalStatus + some numeric covariates
Example results:
crude beta ≈ -1.796 (p ~ 1e-5)
adjusted beta ≈ -1.660 (p ~ 0.0012) — association remains after covariate adjustment (attenuated slightly)
interaction term (exposure * Marital Status): main effect ~ -2.91 (p≈0.0047), interaction for Single vs base p≈0.13 (not significant) — suggests the association is present, and while effect size differs numerically between groups, the difference is not statistically significant (in that interaction test).
Saved summary: adjusted_models_summary.csv
Statistical methods used and why
Correlation
Pearson r for linear relationships; Spearman for rank (nonparametric) association.
SciPy's pearsonr/spearmanr used where possible.
Group comparisons
One-way ANOVA for comparing numeric outcome across categories (assumes approximate normality).
If ANOVA call fails or assumptions questionable, Kruskal-Wallis (nonparametric) fallback is used.
Contingency
Chi-square test for categorical vs categorical contingency tables.
Multiple comparisons
Benjamini–Hochberg (FDR) applied to the set of parsed p-values from relation_summary.csv to control the false discovery rate.
Regression / confounding checks
OLS regression (statsmodels) to estimate crude and adjusted effects and test covariate impact and interactions.
How confounding was handled / what I did to check for it
Controlled confounders (example): age, income_midpoint, education, marital status were included in adjusted linear models.
Compared crude vs adjusted effect sizes:
If the exposure coefficient changes meaningfully after adjustment, that suggests confounding.
In the example, the coefficient shrank slightly after adjustment but remained significant (so confounding partly explains, but does not remove, the association).

Stratified/interaction checks:
I added marital-status stratified visualizations (scatter + regression) and fit interaction models for exposure * Marital Status to test effect heterogeneity.
Notes on completeness:
These adjustments reduce confounding bias for measured covariates, but they do not remove unmeasured confounders or guarantee causal interpretation.
Causal claims — what is and isn’t supported



Not supported:
Strong causal claims (e.g., "Internet use causes lower social support") are not supported by these analyses alone because the data are cross‑sectional (single time point). Cross‑sectional associations can reflect reverse causality, confounding, or selection bias.

What would strengthen causal inference:
Longitudinal / panel data (exposure measured before outcome).
Randomized interventions, or natural experiments.
Instrumental variables with a valid instrument (rare and hard to find).
Careful DAG specifying variables to adjust for and sensitivity analyses for unmeasured confounding (E-values, bias formulas).
Practical conclusion you can make from the current work:


There are consistent, often moderate negative associations between several Internet-problem scales (Withdrawl, Compulsive Behaviour, Occupational/Relationship Consequences, Obsession) and perceived social support / self‑concept scales. These associations persist after adjustment for common sociodemographic covariates in example models, but they are associative (not causal).


Reproducibility — commands to re-run the whole pipeline


1) Run the descriptive analysis:
python3 analysis_scales.py 20251214-ScalesData-Combined_ver0.7-Cleaned-IncomeNormalized.csv

2) Recreate NoOutliers with the relaxed rule and generate plots:
python3 remove_outliers_and_regen.py 20251214-ScalesData-Combined_ver0.7-Cleaned-IncomeNormalized.csv
(This writes the NoOutliers CSV and regenerates InputData/outputs_nooutliers/plots and PDF.)

3) Re-run relational analysis (uses SciPy now):
python3 relational_analysis.py 20251214-ScalesData-Combined_ver0.7-Cleaned-IncomeNormalized-NoOutliers.csv

4) Recompute BH-corrected p-values (I already wrote code that parsed relation_summary.csv and created relation_summary_with_fdr.csv; you can re-run that snippet if you regenerate relation_summary.csv).



Parameters you can tune (and where)
Outlier rule (in remove_outliers_and_regen.py):
min_outlier_cols (default I set = 2). Increase to 3 to be more permissive; set to 1 to be aggressive.
iqr_multiplier (default 1.5). Increase to 2.0 or 3.0 to widen fences.
Relational analysis:
Which INDEP / DEPEND lists are used: edit INDEP and DEPEND lists near the top of relational_analysis.py to focus on a smaller set of exposures/outcomes.
Minimum pairwise sample size threshold (the code currently skips very small groups).
Regression models
Choice of covariates (I used a small set for the Withdrawl example). Add/remove covariates to reflect your proposed DAG.

Practical next steps I recommend (pick one)
	A: Batch adjusted regressions: run adjusted models (same covariates) for a list of internet-related exposures vs key outcomes (Perceived Social Support totals and Self Concept totals). I can produce a CSV of all adjusted coefficients, p-values and BH corrected p-values.
	B: Sensitivity analysis: run models on both the strict NoOutliers (previously 66 rows) and the relaxed NoOutliers (79 rows) and compare results to assess robustness.
	C: Add CLI flags to remove_outliers_and_regen.py for --min-outlier-cols and --iqr-mult, so you can experiment w/o editing code.
	D: Create a one-page PDF "findings summary" with the top 6 associations (plots + adjusted coefficients + FDR q-values) and a short paragraph about confounding and causality.


Anything you want changed now?

I can run any of the next steps immediately. Which do you prefer I do next?
Run batch adjusted regressions for all internet-exposures → key outcomes (A),
Add CLI flags for the outlier script (C),
Create the short summary PDF (D),
Or run the sensitivity check comparing strict vs relaxed outlier rules (B).
If you want A (batch adjusted regressions), tell me:

which exposures (if not the whole internet-related set), and
which outcomes (e.g., Perceived Social Support totals, Social Self Concept Total, Real Self Concept Total).
If you want D (one-page summary), I’ll put the top 6 associations (by absolute adjusted beta) into a single PDF slide with plots and BH-adjusted p-values.

Finally — small housekeeping I can do while you decide:

Add statsmodels and statsmodels version to requirements.txt (I can pin it).
Add a small README note on how to tune the outlier rule.
Pick the next action and I’ll run it and attach the files.


========================================================================================================


Produce adjusted regression results for a predefined list of exposure→outcome pairs (not just Withdrawl → Perceived Social Support). 



Create a python script to batch-run OLS models with the same covariates (Covariates: Age (IN YEARS), Monthly household income_midpoint_INR, Highest level of education completed, Marital Status) for all internet-related exposures and the top dependent scores, then FDR-correct the exposure p-values across those models.


create a MS Word summary showing:
Top 10 associations (plots + BH-adjusted p-values)
Results of 1-2 adjusted regression models (coef, 95% CI, p)
Also create a detailed confounding & causal assessment
======================================================================================================

Based on the OLS model analysis done for internet-related exposures and the dependent scores modulated with Covariates: Age (IN YEARS), Monthly household income_midpoint_INR, Highest level of education completed, Marital Status  ----- what is the analysis of relationship between the internet-related exposures and the dependent scores



=========================================================================================================

Please update the remove_outliers_and_regen.py script to also create a MS word document. The contents of this word document need to be same exactly as the pdf. Make sure the content in the word document and the PNGs & PDF is very legible. No over writing on text on the titles, axis, summary comments etc. 


==========================================================================================================


For the above analysis done write a commentary that will work as part of the thesis write up that will be done for my PhD Titled "Social Networking and Its Impact on Perceived Stress, Self-Concept & Social Support of Married Females versus Un-Married Females". 

Following scales (questionnaires) were decided to be used: 

1) Internet Overuse Scale By Dr. Darshna Shah (Vallabh Vidyanagar) & Prof. Urmi Nanda Biswas (Vadodara)

2) Self CONCEPT Scale by R. K. Saraswat, Ph.D.

3) Perceived Social Support by 
Dr. Madhu Asthana, Head, Department of Psychology Sri Agrasen Kanya Autonomous P. G. College, Varanasi
Dr. Dr. Kiran Bala Verma, Head, Department of Psychology Harishchandra P. G. College Varanasi.

4) Perceived Stress Scale by Arun K. Singh (Patna) & Ashish Kumar Singh (Patna)

 
Start the write up by telling the objective of the Thesis being -- 

" 
To investigate the multifaceted impact of social networking on the perceived stress levels, self-concept, and social support networks of Indian females in the context of their marital status. 	
By addressing these questions, this research seeks to provide valuable insights into the complex interplay between social networking, psychological well-being, and social relationships among Indian women, shedding light on the unique experiences and challenges faced by both married and unmarried individuals in the digital age.
" 


Then tell based on questionnaire what were the independent & dependent variables. 
List of independent & dependent variables are as below. 

Tell following valiables will be are covariates.  

	Age (IN YEARS)
	Marital Status
	Highest level of education completed
	Current Employment Status
	Number of children
	Type of family structure
	Monthly household income
	Access to healthcare services
	Overall health status
	Are you covered by health insurance?
	Participation in community or social activities




Following variables will be used as independent variables - 

	Functional Impairment 
	Withdrawl
	Occupational & Relationship Consequences
	Compulsive Behaviour
	Obsession with Internet
	Internet as a Source of Recreation
	Enhanced Socialization 
	Perceived Control of Internet Use
	Internet Usage Total Score 



Following varibales will be used as dependent variables: 

	Emotional Support 
	Informational Support 
	Instrumental Support 
	Perceived Social Support Total Score 	

	Power Self Concept - Real Self Concept Score	
	Power Self Concept - Ideal Self Concept score	
	Power Self Concept – Social Self Concept Score	
	Social Self Concept - Real Self Concept Score	
	Social Self Concept – Ideal Self Concept Score 	
	Social Self Concept – Social Self Concept Score	
	Ability Self Concept - Real Self Concept Score	
	Ability Self Concept - Ideal Self Concept Score	
	Ability Self Concept – Social Self Concept Score	
	Physical Self Concept - Real Self Concept Score	
	Physical Self Concept – Ideal Self Concept Score	
	Physical Self Concept – Social Self Concept Score	
	Psychological Self Concept - Real Self Concept Score	
	Psychological Self Concept – Ideal Self Concept Score	
	Psychological Self Concept – Social Self Concept Score	
	Real Self Concept Total Score	
	Ideal Self Concept Total Score	
	Social Self Concept Total Score


Then explain the statistical analysis that was done - 

- Based on the files /home/pranav/PhD-Jaya/InputData/categorical_summary.csv & /home/pranav/PhD-Jaya/InputData/numeric_stats.csv -  Describe the descriptive analysis done for the variables. 
- Summarize the findings for descriptive statistical analysis in terms of what are the observed patterns, outliers, means, medians, standard deviations, ranges, skewness of data as shown in histograms and quartile charts. Make comments by each variable if the data is well distributed or not.  

Add all of the above analysis to a well formatted MS Word document 

======================================

Now explain the statistical analysis that was done - 

- Based on the output data in the file "/home/pranav/PhD-Jaya/InputData/relation_summary.csv" pearson/spearman, ANOVA & Chi-square tests that were done to find causal and associative relationship between the internet-related exposures, demographic covariates and dependent variables 
- Summarize the key findings from pearson/spearman, ANOVA & Chi-square tests:  
	- For each person/spearman test done provide comments on strength/direction of relationship between independent/covariate and dependent basis the "r" & "p" values 
	- For each ANOVA test done provide comments on strength of relationship between independent/covariate and dependent basis the "F" & "p" values  
	- For each Chi-square test done provide comments on non-random associations between independent/covariate and dependent basis the "χ²" & "p" values  

Add all of the above analysis to a well formatted MS Word document 
====================================================
- Describe the OLS regression that was done to find relationship between for all internet-related exposures and the dependent scores / variables
- Provide reason why  Covariates ( that is - Age (IN YEARS), Monthly household income_midpoint_INR, Highest level of education completed, Marital Status were used ) were used in OLS models 


Finally summarize the key findings. 
Based on the OLS model analysis done for internet-related exposures and the dependent scores modulated with Covariates: Age (IN YEARS), Monthly household income_midpoint_INR, Highest level of education completed, Marital Status  ----- what is the analysis of relationship between the internet-related exposures and the dependent scores

Add charts to support the numbers shown in tables on : 
- Key findings from ANOVA & Chi-square tests
- Key Findings from OLS Models
(take png generated by scripts analysis_scales.py, produce_report.py, emove_outliers_and_regen.py, relational_analysis.py ) 


Add all of the above analysis to a well formatted MS Word document 
 

===========================================================



The /home/pranav/PhD-Jaya/scripts/relational_analysis.py script does relationship analysis using the following independent variables - 


Age (IN YEARS)
Marital Status
Highest level of education completed
Current Employment Status
Number of children
Type of family structure
Monthly household income
Access to healthcare services
Overall health status
Are you covered by health insurance?
Participation in community or social activities
Functional Impairment - Raw Score


But relationship analysis using the following independent variables is not done -- 


Functional Impairment - Raw Score
Withdrawl - Raw Score
Occupational & Relationship Consequences - Raw Score
Compulsive Behaviour - Raw Score
Obsession with Internet - Raw Score
Internet as a Source of Recreation - Raw Score
Enhanced Socialization - Raw Score
Perceived Control of Internet Use - Raw Score
Functional Impairment - Weighted Score
Withdrawl - Weighted Score
Occupational & Relationship Consequences - Weighted Score
Compulsive Behaviour - Weighted Score
Obsession with Internet - Weighted Score
Internet as a Source of Recreation - Weighted Score
Enhanced Socialization - Weighted Score
Perceived Control of Internet Use - Weighted Score
Internet Usage Total Score (Weighted)
Functional Impairment  - Category
Withdrawl – Category
Occupational & Relationship Consequences – Category
Compulsive Behaviour – Category
Obsession with Internet – Category
Internet as a Source of Recreation – Category
Enhanced Socialization - Category 
Perceived Control of Internet Use - Category 
Internet Usage Total Categoty


can you tell the reason why ? 


=================================================================================================




